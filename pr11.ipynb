{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131f449e",
   "metadata": {},
   "source": [
    "To develop a GRU-based RNN model for sentiment analysis on the IMDB movie reviews dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbdff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.6756 - loss: 0.5619 - val_accuracy: 0.8326 - val_loss: 0.3796\n",
      "Epoch 2/3\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.8924 - loss: 0.2706 - val_accuracy: 0.8442 - val_loss: 0.3493\n",
      "Epoch 3/3\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9276 - loss: 0.1909 - val_accuracy: 0.8554 - val_loss: 0.4161\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.4208\n",
      "\n",
      "Test Accuracy: 0.8544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Sentiment: positive | Score: 1.00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Sentiment: negative | Score: 0.08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# Load IMDB dataset (top 10,000 words), pad to length 200\n",
    "num_words, maxlen = 10000, 200\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "x_train, x_test = pad_sequences(x_train, maxlen=maxlen), pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# Build GRU-based model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(num_words, 128),     # Converts word indices to dense vectors\n",
    "    GRU(64),                        # GRU layer for sequence learning\n",
    "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile and train model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test data\n",
    "_, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Prediction function\n",
    "def sent(r):\n",
    "    p = pad_sequences([r], maxlen=maxlen)  # pad the input review\n",
    "    s = model.predict(p)[0][0]             # get prediction score\n",
    "    print(f\"Sentiment: {'positive' if s >= 0.5 else 'negative'} | Score: {s:.2f}\")\n",
    "\n",
    "# Show examples\n",
    "sent(x_test[np.where(y_test == 1)[0][0]])  # sample positive\n",
    "sent(x_test[np.where(y_test == 0)[0][0]])  # sample negative"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
