{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711fb449",
   "metadata": {},
   "source": [
    "Aim:  Develop a Python script to execute various learning rules commonly \n",
    "employed in deep learning, including the Hebbian Learning Rule, Perceptron \n",
    "Learning Rule, Delta Learning Rule, Correlation Learning Rule, and OutStar \n",
    "Learning Rule.\n",
    " Tools: None\n",
    " Procedure:\n",
    " 1) Initialize the input vectors associated with the target values.\n",
    " 2) Initialize the weights and bias.\n",
    " 3) Set learning rules.\n",
    " 4) Input layer has a unique activation function.\n",
    " 5) Calculate the output.\n",
    " 6) Make adjustments of weights comparing the desired output and target values.\n",
    " 7) Continue the iterations until there is no change of weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3afe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hebbian Weights: [2 1 1]\n",
      "Perceptron Weights: [-0.1 -0.1 -0.1]\n",
      "Delta Rule Weights: [0.3635668  0.00736712 0.04971017]\n",
      "Correlation Weights: [2 1 1]\n",
      "OutStar Weights: [0.86496482 0.83262047 0.12363405 0.14213803]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input and target\n",
    "X = np.array([\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 0]\n",
    "])\n",
    "T = np.array([1, 1, 0, 0])\n",
    "\n",
    "# Parameters\n",
    "epochs, lr = 10, 0.1\n",
    "\n",
    "# Activation function (step)\n",
    "activation = lambda x: np.where(x >= 0, 1, 0)\n",
    "\n",
    "# Hebbian Learning\n",
    "W_hebb = np.sum([x * t for x, t in zip(X, T)], axis=0)\n",
    "\n",
    "# Perceptron Learning\n",
    "W_perceptron = np.zeros(X.shape[1])\n",
    "for _ in range(epochs):\n",
    "    for x, t in zip(X, T):\n",
    "        y = activation(np.dot(x, W_perceptron))\n",
    "        W_perceptron += lr * (t - y) * x\n",
    "\n",
    "# Delta Learning (Widrow-Hoff Rule)\n",
    "W_delta = np.zeros(X.shape[1])\n",
    "for _ in range(epochs):\n",
    "    for x, t in zip(X, T):\n",
    "        y = np.dot(x, W_delta)\n",
    "        W_delta += lr * (t - y) * x\n",
    "\n",
    "# Correlation Learning (dot product for single output)\n",
    "W_corr = np.dot(T, X)\n",
    "\n",
    "# OutStar Learning (based on convergence to T)\n",
    "W_outstar = np.random.rand(len(T))\n",
    "for _ in range(epochs):\n",
    "    W_outstar += lr * (T - W_outstar)\n",
    "\n",
    "# Output results\n",
    "print(\"Hebbian Weights:\", W_hebb)\n",
    "print(\"Perceptron Weights:\", W_perceptron)\n",
    "print(\"Delta Rule Weights:\", W_delta)\n",
    "print(\"Correlation Weights:\", W_corr)\n",
    "print(\"OutStar Weights:\", W_outstar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14da210-ae6c-4891-a628-cc4d87c119a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
